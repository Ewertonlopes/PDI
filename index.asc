:source-highlighter: pygments
:toc: left
:stem:

= Atividades Práticas Processamento Digital de Imagens =
Ewerton Vasoncelos Lopes <ewerton.lopes.140@ufrn.edu.br>

O relatório a seguir diz respeito a todas atividades referentes às práticas desenvolvidas para a disciplina de Processamento Digital de Imagens - DCA0445 durante o período de 2023.2 na Universidade Federal do Rio Grande do Norte.

== Atividade 1: Manipulando Pixels

As primeiras atividades possuem um caráter introdutório para trabalhar o desenvolvimento da manipulação dos pixels de uma dada imagem qualquer. Para desenvolver essa competência se utilizou do desenvolvimento de um negativo de uma área de uma dada imagem de entrada e a reordenação de uma imagem em seus quadrantes.

=== Criando Negativo

O desenvolvimento de um negativo de uma área é feito de forma simples com uma entrada de uma imagem qualquer pelo argumento de linha de comando e uma entrada cin posterior de dois pontos.

[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

int main(int argc, char** argv)
{
    cv::Mat image;
    cv::Vec3b val;
    
    cv::Point p1,p2;

    image = cv::imread(argv[1],cv::IMREAD_GRAYSCALE);
    
    do
    {
        std::cout<<"Ponto Inicial (x y):"; 
        std::cin>>p1.x>>p1.y;
    }while(p1.x > image.rows || p1.y > image.cols);

    do
    {
        std::cout<<"Ponto Final (x y):";
        std::cin>>p2.x>>p2.y;
    }while(p2.x > image.rows || p2.y > image.cols);

    int xin, xout, yin, yout;
    if(p1.x > p2.x){xin = p2.x; xout = p1.x;}
    else{xin = p1.x; xout = p2.x;} 

    if(p1.y > p2.y){yin = p2.y; yout = p1.y;}
    else {yin = p1.y; yout = p2.y;}

    for(int i = xin; i<=xout; i++)
    {
        for(int j = yin; j<yout; j++)
        {
            image.at<uchar>(i,j) = 255 - image.at<uchar>(i,j);
        }
    }

    cv::imshow("Negative", image);
    cv::waitKey();

    return 0;
}
----

A geração do negativo pode ser evidenciado pela parte do código logo abaixo onde se retira o valor da posição de cada pixel do valor de 255 no caso de usarmos um unsigned char para a geração da imagem.

[source,cpp]
----
for(int i = xin; i<=xout; i++)
{
    for(int j = yin; j<yout; j++)
    {
        image.at<uchar>(i,j) = 255 - image.at<uchar>(i,j);
    }
}
----

O resultado obtido pode ser visto na figura <<fig_neg>>.

[[fig_neg, Negativo]]
.Saída do programa negativo
image::images/negative.png[title="Execução do Programa em Negativo"]


=== Invertendo Quadrantes

O processo de inverter quadrantes segue uma lógica muito parecida com a que foi aplicada na atividade anterior. Apenas dessa vez devemos fazer isso de forma fixa a depender das dimensões da imagem. Porém, como forma de aprofundar os conhecimentos da biblioteca do openCV, se resolveu utilizar outros métodos internos a api sem o uso de loops externos e acessos aos pixels individuais. Como podemos ver no código logo abaixo a imagem foi repartida em quatro pedaços menores que a posteriori foram unidos nas posições corretas.

[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

int main(int argc, char** argv)
{
    cv::Mat image;
    cv::Vec3b val;
    
    image = cv::imread(argv[1],cv::IMREAD_GRAYSCALE);
   
    cv::Mat sub11out = image(cv::Range(0,(image.rows/2) - 1), cv::Range(0,(image.cols/2) - 1));
  cv::Mat sub12out = image(cv::Range(0,(image.rows/2) - 1), cv::Range(image.cols/2,image.cols));
    cv::Mat sub21out = image(cv::Range(image.rows/2,image.rows), cv::Range(0,(image.cols/2)));
  cv::Mat sub22out = image(cv::Range(image.rows/2,image.rows), cv::Range(image.cols/2,image.cols));

    cv::Mat aux = image.clone();

    sub22out.copyTo(aux(cv::Rect(0,0,sub22out.cols, sub22out.rows)));
    sub12out.copyTo(aux(cv::Rect(0,image.cols/2,sub12out.cols, sub12out.rows)));
    sub21out.copyTo(aux(cv::Rect(image.rows/2,0,sub21out.cols, sub21out.rows)));
    sub11out.copyTo(aux(cv::Rect(image.rows/2,image.cols/2,sub11out.cols, sub11out.rows)));
    
    cv::imshow("Inverse", aux);
    cv::waitKey();

    return 0;
}
----

O resultado obtido pode ser visto na figura <<fig_quad>>.

[[fig_quad, Quadrants]]
.Saída do programa Quadrantes
image::images/quadrants.png[title="Saída do Programa Quadrantes."]


== Atividade 2: Salvando Imagens

A atividade seguinte foi desenvolvida para melhorar a compreensão do estudante quanto às formas de se guardar as imagens em um computador. Abaixo temos o código desenvolvido nesta atividade.

[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>
#include <sstream>
#include <string>

int SIDE = 256;
int PERIODOS = 4;

int main(int argc, char** argv) 
{
  std::stringstream ss_img, ss_yml;
  cv::Mat image;

  ss_yml << "senoide-" << SIDE << ".yml";
  image = cv::Mat::zeros(SIDE, SIDE, CV_32FC1);

  cv::FileStorage fs(ss_yml.str(), cv::FileStorage::WRITE);

  for (int i = 0; i < SIDE; i++) {
    for (int j = 0; j < SIDE; j++) {
      image.at<float>(i, j) = 127 * sin(2 * M_PI * PERIODOS * j / SIDE) + 128;
    }
  }

  fs << "mat" << image;
  fs.release();

  cv::normalize(image, image, 0, 255, cv::NORM_MINMAX);
  image.convertTo(image, CV_8U);
  ss_img << "senoide-" << SIDE << ".png";
  cv::imwrite(ss_img.str(), image);

  fs.open(ss_yml.str(), cv::FileStorage::READ);
  fs["mat"] >> image;

  cv::normalize(image, image, 0, 255, cv::NORM_MINMAX);
  image.convertTo(image, CV_8U);

  cv::imshow("image", image);
  cv::waitKey();
}
----

Ao abrirmos os arquivos resultantes temos um arquivo que só pode ser compreendido por um visualizador de imagens gerado pelo png, como demonstra a figura <<fig_png>>, e um arquivo que pode ser facilmente compreendido por seres humanos no arquivo yml, sem contar as incontáveis possibilidades de que os dados podem ser salvos no formato yml, como demonstra a figura <<fig_yml>>.

[[fig_png, ImagensPng]]
.Saída do programa para a imagem PNG
image::images/imagempng.png[title="Dados no arquivo png."]

[[fig_yml, ImagensYML]]
.Saída do programa para o arquivo yml
image::images/imagemyml.png[title="Dados no arquivo yml."]

== Atividade 3: Esteganografia de uma imagem

Partindo de uma imagem que possuía uma segunda imagem escondida, esta atividade retorna a manipulação de pixels. Dessa vez é necessário fazer o movimento contrário do qual foi feita para se esconder a imagem. 

[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

int main(int argc, char**argv) {
  	cv::Mat imagemPortadora, imagemEscondida, imagemFinal;
 	cv::Vec3b valPortadora, valEscondida, valFinal;
	int nbits = 3;

	imagemFinal = cv::imread(argv[1], cv::IMREAD_COLOR);
	
	imagemPortadora = imagemFinal.clone();
	imagemEscondida = imagemFinal.clone();

  	if (imagemFinal.empty()) 
	{
    	std::cout << "imagem nao carregou corretamente" << std::endl;
    	return (-1);
  	}

  	for (int i = 0; i < imagemFinal.rows; i++) 
	{
    	for (int j = 0; j < imagemFinal.cols; j++) 
		{
			valFinal = imagemFinal.at<cv::Vec3b>(i, j);
		
      		valPortadora[0] = valFinal[0] >> nbits << nbits;
      		valPortadora[1] = valFinal[1] >> nbits << nbits;
      		valPortadora[2] = valFinal[2] >> nbits << nbits;

     		valEscondida[0] = valFinal[0] << (8-nbits);
      		valEscondida[1] = valFinal[1] << (8-nbits);
      		valEscondida[2] = valFinal[2] << (8-nbits);
			
			imagemPortadora.at<cv::Vec3b>(i,j) = valPortadora;
			imagemEscondida.at<cv::Vec3b>(i,j) = valEscondida;	
    	}
  	}

	cv::imshow("Portadora",imagemPortadora);
	cv::waitKey();
	cv::imshow("Escondida",imagemEscondida);
  	cv::waitKey();

  return 0;
}
----

O procedimento é simplesmente pegar os n dígitos mais significativos da imagem e separá-los para uma imagem e pegar os Nbytes - n dígitos menos significativos e colocá-los em uma outra imagem. Como estamos utilizando imagens de 1 byte e um n de 3 foi o suficiente para revelar a imagem escondida, temos então os 5 bits mais significativos da imagem separados dos 3 bits menos significativos. Assim podemos separar as duas imagens como pode ser visto na figura <<fig_esteg>>.

[[fig_esteg, estego]]
.Saída do programa de separação de imagens
image::images/esteg.png[title="Imagem portadora e imagem escondida"]



== Atividade 4: Labeling de Imagens

Para se fazer o labeling primeiro se utilizou de floodfill para fazer a separação dos mais diversos tipos de figuras na tela. Como primeira experiência para resolver todos os problemas, se resolveu implementar um floodfill próprio, não se utilizando da api do opencv, para que assim fosse possível fazer as diversas distinções esperadas pelo problema. Esse código pode ser visto logo abaixo.

[source,cpp]
----
void myfloodFill(cv::Mat img, int r, int c, int targetColor, int newColor, bool* borda)
{
    if (r < 0 || r >= img.rows || c < 0 || c >= img.cols || img.at<uchar>(r,c) != targetColor) return;
    if(r == 0 || c == 0 || r == img.rows-1 || c == img.cols-1) *borda = true;

    img.at<uchar>(r,c) = newColor;

    myfloodFill(img, r+1, c, targetColor, newColor,borda);
    myfloodFill(img, r-1, c, targetColor, newColor,borda);
    myfloodFill(img, r, c+1, targetColor, newColor,borda);
    myfloodFill(img, r, c-1, targetColor, newColor,borda);
}
----

Dessa forma seria possível continuar com essa linha de pensamento, porém, o openCV dispões de formas muito mais eficientes de resolver esse problema. Utilizando qualquer floodfill para se livrar das bolhas que tocam as bordas e em seguida passando pela função findContours do OpenCV.

[source,cpp]
----
    std::vector<std::vector<cv::Point> > contours;
    std::vector<cv::Vec4i> hierarchy;
    cv::findContours(image, contours, hierarchy, cv::RETR_TREE, cv::CHAIN_APPROX_SIMPLE);
     for(unsigned i = 0; i< hierarchy.size();i++)
    {
      if(hierarchy[i][3]<0 && hierarchy[i][2]<0)
      {
          solido++;
      }
      else if(hierarchy[i][3]>0)
      {
          buraco++;
      }
    }
----

Utilizando da lógica hierárquica recebida no vetor hierarchy é possível, então, definir quais bolhas são internas e as bolhas são externas. Com essa lógica é possível resolver a limitação máxima do labeling, assim como, definir bolhas internas a qualquer nível, ou seja, é possível entender qual grau de interno é uma bolha mesmo que tenhamos dezenas de bolhas se englobando. É ainda possível se utilizar de métricas do próprio openCV para calcular médias, detectar figuras, entre outros fins. Abaixo podemos ver o código completo.
[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

void myfloodFill(cv::Mat img, int r, int c, int targetColor, int newColor, bool* borda)
{
    if (r < 0 || r >= img.rows || c < 0 || c >= img.cols || img.at<uchar>(r,c) != targetColor) return;
    if(r == 0 || c == 0 || r == img.rows-1 || c == img.cols-1) *borda = true;

    img.at<uchar>(r,c) = newColor;

    myfloodFill(img, r+1, c, targetColor, newColor,borda);
    myfloodFill(img, r-1, c, targetColor, newColor,borda);
    myfloodFill(img, r, c+1, targetColor, newColor,borda);
    myfloodFill(img, r, c-1, targetColor, newColor,borda);
}


int main(int argc, char** argv) {
  cv::Mat image;
  int width, height;

  image = cv::imread(argv[1], cv::IMREAD_GRAYSCALE);

  if (!image.data) {
    std::cout << "imagem nao carregou corretamente\n";
    return (-1);
  }

  width = image.cols;
  height = image.rows;
  std::cout << width << "x" << height << std::endl;

  // Preprocessando Imagem
  
  for (int i = 0; i < height; i++) {
    for (int j = 0; j < width; j++) {
      if (image.at<uchar>(i, j) == 255) {
        bool borda = false;

        myfloodFill(image, i,j,255,254,&borda);
        if(borda)
        {
            myfloodFill(image,i,j,254,0,&borda);
        }
        else
        {
            myfloodFill(image,i,j,254,255,&borda);
        }
      }
    }
  }
  
  int buraco = 0;
  int solido = 0;

  // Utilizando busca de contornos da openCV
  //
  std::vector<std::vector<cv::Point> > contours;
  std::vector<cv::Vec4i> hierarchy;
  cv::findContours(image, contours, hierarchy, cv::RETR_TREE, cv::CHAIN_APPROX_SIMPLE);
  
  for(unsigned i = 0; i< hierarchy.size();i++)
  {
      if(hierarchy[i][3]<0 && hierarchy[i][2]<0)
      {
          solido++;
      }
      else if(hierarchy[i][3]>0)
      {
          buraco++;
      }
  }

  std::cout << "a figura tem " << buraco+solido << " bolhas\n";
  std::cout << "Sendo " << buraco << " com buracos\n";
  std::cout << "Sendo " << solido << " solidas\n";
  
  std::vector<cv::Moments> mu(contours.size());
  for (size_t i = 0; i< contours.size();i++)
  {
      mu[i] = cv::moments(contours[i]);
  }

   for( size_t i = 0; i < contours.size(); i++ )
 {
     if(hierarchy[i][3]<0 && hierarchy[i][2]<0)
     {
        std::cout <<  "SOLIDO: " << i<< std::endl;;
        std::cout << "Area (M_00) = " << std::fixed << std::setprecision(2) << mu[i].m00 << std::endl<<std::endl;
     }
     else if(hierarchy[i][3]>0)
     {
        std::cout << "Com Buraco: " <<i<< std::endl;
        std::cout <<  "Area (M_00) = " << std::fixed << std::setprecision(2) << mu[i].m00<<std::endl<<std::endl;
     }
     else
     {
        std::cout << "Buraco: " <<i<< std::endl;
        std::cout <<  "Area (M_00) = " << std::fixed << std::setprecision(2) << mu[i].m00<<std::endl<<std::endl;
     }
 }

  cv::drawContours(image,contours,-1,127,2);

  cv::imshow("image", image);
  cv::imwrite("labeling.png", image);
  cv::waitKey();
  return 0;
}
----

A saída desse programa pode ser visto na figura <<fig_label>>

[[fig_label, labeling]]
.Saída do programa de labeling
image::images/label.png[title="Saída do programa de labeling"]


== Atividade 5: Histogramas

Trabalhar com imagens capturadas por uma câmera de vídeo acaba se tornando em uma série de trabalhos em imagens estáticas que deve ser feita de forma muito rápida. Nos programas dessa atividade é necessário processar em cima das imagens recebidas por uma câmera, sendo a primeira delas uma operação de equalização que tenta filtrar as mudanças bruscas de iluminação, enquanto para a segunda teremos de desenvolver um sensor de movimento.

=== Equalização

A equalização é feita de forma simples, após obter a imagem e transformá-la em tons de cinza essa deve ser normalizada com o comando normalize, isso deve ser feito nos 3 canais de cor. Em seguida basta mostrar a saída dessa imagem, podemos ver no código logo abaixo.

[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>

int main(int argc, char** argv)
{
  cv::Mat image;
  int width, height;
  cv::VideoCapture cap;
  std::vector<cv::Mat> planes;
  cv::Mat histR, histG, histB;
  int nbins = 64;
  float range[] = {0, 255};
  const float *histrange = { range };
  bool uniform = true;
  bool acummulate = false;
  int key;

  cap.open(0);
  
  if(!cap.isOpened()){
    std::cout << "cameras indisponiveis";
    return -1;
  }
  
  cap.set(cv::CAP_PROP_FRAME_WIDTH, 640);
  cap.set(cv::CAP_PROP_FRAME_HEIGHT, 480);  
  width = cap.get(cv::CAP_PROP_FRAME_WIDTH);
  height = cap.get(cv::CAP_PROP_FRAME_HEIGHT);

  std::cout << "largura = " << width << std::endl;
  std::cout << "altura  = " << height << std::endl;

  int histw = nbins, histh = nbins/2;
  cv::Mat histImgR(histh, histw, CV_8UC3, cv::Scalar(0,0,0));
  cv::Mat histImgG(histh, histw, CV_8UC3, cv::Scalar(0,0,0));
  cv::Mat histImgB(histh, histw, CV_8UC3, cv::Scalar(0,0,0));

  while(1){
    cap >> image;
    cv::split (image, planes);
    cv::calcHist(&planes[0], 1, 0, cv::Mat(), histB, 1,
                 &nbins, &histrange,
                 uniform, acummulate);
    cv::calcHist(&planes[1], 1, 0, cv::Mat(), histG, 1,
                 &nbins, &histrange,
                 uniform, acummulate);
    cv::calcHist(&planes[2], 1, 0, cv::Mat(), histR, 1,
                 &nbins, &histrange,
                 uniform, acummulate);
    
    cv::normalize(histR, histR, 0, histImgR.rows, cv::NORM_MINMAX, -1, cv::Mat());
    cv::normalize(histG, histG, 0, histImgG.rows, cv::NORM_MINMAX, -1, cv::Mat());
    cv::normalize(histB, histB, 0, histImgB.rows, cv::NORM_MINMAX, -1, cv::Mat());
    
    histImgR.setTo(cv::Scalar(0));
    histImgG.setTo(cv::Scalar(0));
    histImgB.setTo(cv::Scalar(0));
    
    for(int i=0; i<nbins; i++){
      cv::line(histImgR,
               cv::Point(i, histh),
               cv::Point(i, histh-cvRound(histR.at<float>(i))),
               cv::Scalar(0, 0, 255), 1, 8, 0);
      cv::line(histImgG,
               cv::Point(i, histh),
               cv::Point(i, histh-cvRound(histG.at<float>(i))),
               cv::Scalar(0, 255, 0), 1, 8, 0);
      cv::line(histImgB,
               cv::Point(i, histh),
               cv::Point(i, histh-cvRound(histB.at<float>(i))),
               cv::Scalar(255, 0, 0), 1, 8, 0);
    }
    histImgR.copyTo(image(cv::Rect(0, 0       ,nbins, histh)));
    histImgG.copyTo(image(cv::Rect(0, histh   ,nbins, histh)));
    histImgB.copyTo(image(cv::Rect(0, 2*histh ,nbins, histh)));
	cv::Mat gray;
	cv::cvtColor(image,gray,cv::COLOR_BGR2GRAY);
	
	cv::Mat dst;
	cv::equalizeHist(gray,dst);
    cv::imshow("image", dst);
    key = cv::waitKey(30);
    if(key == 27) break;
    return 0;
}
----

A equalização torna a imagem mais resistente às mudanças e, portanto, torna a imagem mais estável. A imagem pode ser vista na figura <<fig_equal>>.


[[fig_equal, equalize]]
.Saída do programa de equalização
image::images/equal.png[title="Saída do programa de Equalização da câmera"]

=== Sensor de presença

Para desenvolver um sensor de presença devemos trabalhar com o conceito de média de uma imagem. Para essa atividade se mantém o desenvolvimento da média de forma constante a cada frame, sempre guardando a média das últimas imagens e o delta da imagem anterior para a média. Quando esse delta ultrapassa um limiar, no caso 10 em qualquer escala de cor, o sistema lança um aviso de alarme escrito e salva uma imagem do que foi capturada pelo sensor de presença. Abaixo podemos ver o código desse sensor.

[source,cpp]
----
#include <iostream>
#include <opencv2/opencv.hpp>
#include <cmath>

int main(int argc, char** argv){
  cv::Mat image;
  int width, height;
  cv::VideoCapture cap;
  std::vector<cv::Mat> planes;
  cv::Mat histR, histG, histB;
  int nbins = 64;
  float range[] = {0, 255};
  const float *histrange = { range };
  bool uniform = true;
  bool acummulate = false;
  int key,number = 0;
  float mRed,mGreen,mBlue;
  float dRed,dGreen,dBlue;
  float lRed = 0.0;
  float lGreen = 0.0;
  float lBlue = 0.0;
  

  cap.open(0);
  
  if(!cap.isOpened()){
    std::cout << "cameras indisponiveis";
    return -1;
  }
  
  cap.set(cv::CAP_PROP_FRAME_WIDTH, 640);
  cap.set(cv::CAP_PROP_FRAME_HEIGHT, 480);  
  width = cap.get(cv::CAP_PROP_FRAME_WIDTH);
  height = cap.get(cv::CAP_PROP_FRAME_HEIGHT);

  std::cout << "largura = " << width << std::endl;
  std::cout << "altura  = " << height << std::endl;

  int histw = nbins, histh = nbins/2;
  cv::Mat histImgR(histh, histw, CV_8UC3, cv::Scalar(0,0,0));
  cv::Mat histImgG(histh, histw, CV_8UC3, cv::Scalar(0,0,0));
  cv::Mat histImgB(histh, histw, CV_8UC3, cv::Scalar(0,0,0));

  while(1){
    cap >> image;

    cv::split (image, planes);
    cv::calcHist(&planes[0], 1, 0, cv::Mat(), histB, 1,
                 &nbins, &histrange,
                 uniform, acummulate);
    cv::calcHist(&planes[1], 1, 0, cv::Mat(), histG, 1,
                 &nbins, &histrange,
                 uniform, acummulate);
    cv::calcHist(&planes[2], 1, 0, cv::Mat(), histR, 1,
                 &nbins, &histrange,
                 uniform, acummulate);
    
    cv::normalize(histR, histR, 0, histImgR.rows, cv::NORM_MINMAX, -1, cv::Mat());
    cv::normalize(histG, histG, 0, histImgG.rows, cv::NORM_MINMAX, -1, cv::Mat());
    cv::normalize(histB, histB, 0, histImgB.rows, cv::NORM_MINMAX, -1, cv::Mat());
    
    histImgR.setTo(cv::Scalar(0));
    histImgG.setTo(cv::Scalar(0));
    histImgB.setTo(cv::Scalar(0));
    
    for(int i=0; i<nbins; i++){
      cv::line(histImgR,
               cv::Point(i, histh),
               cv::Point(i, histh-cvRound(histR.at<float>(i))),
               cv::Scalar(0, 0, 255), 1, 8, 0);
      cv::line(histImgG,
               cv::Point(i, histh),
               cv::Point(i, histh-cvRound(histG.at<float>(i))),
               cv::Scalar(0, 255, 0), 1, 8, 0);
      cv::line(histImgB,
               cv::Point(i, histh),
               cv::Point(i, histh-cvRound(histB.at<float>(i))),
               cv::Scalar(255, 0, 0), 1, 8, 0);
    }
    histImgR.copyTo(image(cv::Rect(0, 0       ,nbins, histh)));
    histImgG.copyTo(image(cv::Rect(0, histh   ,nbins, histh)));
    histImgB.copyTo(image(cv::Rect(0, 2*histh ,nbins, histh)));
    
    cv::Scalar amean = cv::mean(image);
    mRed = amean.val[0];
    mGreen = amean.val[1];
    mBlue = amean.val[2];
    
    dRed = mRed - lRed;
    dGreen = mGreen - lGreen;
    dBlue = mBlue - lBlue;

    lRed = mRed;
    lGreen = mGreen;
    lBlue = mBlue;

    if(dRed>10 || dGreen>10 || dBlue>10)
    {
        std::cout<<"-----------ALARM-------------"<<std::endl;
        std::stringstream ss_img;
        ss_img<<"Alarms/Alarm"<<number++<<".png";
        cv::imwrite(ss_img.str(),image);
    }

    
    cv::imshow("image", image);
    key = cv::waitKey(30);
    if(key == 27) break;
  }
  return 0;
}
----

O funcionamento desse sistema de alarme pode ser visto na figura <<fig_alarm>>. Com um simples acesso a uma api de timetag é possível guardar os momentos de acontecimento dos alarmes e tornar este um sistema funcional de baixo custo.


[[fig_alarm, alarme]]
.Saída do programa de alarme
image::images/alarm.png[title="Saída do Programa de Sensor de Movimento"]


stem:[\int_a^b f(x) dx]

